{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rule_based import total_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {0: \"weather\", \n",
    "           1: \"religious time\", \n",
    "           2: \"time\", \n",
    "           3: \"date\", \n",
    "           4: \"unknown\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mh_clean.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model (): \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 100, input_length=maxlen))\n",
    "    model.add(Conv1D(filters=32, kernel_size=16, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    # model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(5, activation='sigmoid'))\n",
    "    # print(model.summary())\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    summary = model.fit(Xtrain, y_train, epochs=15, verbose=0)\n",
    "    eval_summary = model.evaluate(Xtest, y_test, verbose=0)\n",
    "    \n",
    "    return model, eval_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[\"sentence\"].values\n",
    "y = df[\"class\"].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = max([len(s.split()) for s in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_docs = tokenizer.texts_to_sequences(x_train)\n",
    "Xtrain = pad_sequences(enc_docs, maxlen=maxlen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_docs = tokenizer.texts_to_sequences(x_test)\n",
    "Xtest = pad_sequences(enc_docs, maxlen=maxlen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, eval_summary = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sent: str) -> int:\n",
    "    enc_docs = tokenizer.texts_to_sequences(np.array([sent]))\n",
    "    s = pad_sequences(enc_docs, maxlen=maxlen, padding='post')\n",
    "    pred = model.predict(s)\n",
    "    ind = np.argpartition(pred, -2)[-2:].flatten().tolist()\n",
    "    ind.reverse()\n",
    "    \n",
    "    print(f\"The first predicted class: {mapping[ind[0]]}\")\n",
    "    print(f\"The second predicted class: {mapping[ind[1]]}\")\n",
    "    \n",
    "    sc = total_score(sent)\n",
    "    sc[4] = 0\n",
    "    print(sc)\n",
    "    \n",
    "    if sc[ind[0]] >= 2 and sc[ind[1]] <= 2:\n",
    "        return mapping[ind[0]]\n",
    "    elif abs(sc[ind[0]] - sc[ind[1]]) <= 2:\n",
    "        return mapping[ind[0]]  # CHECK THIS PLEASE\n",
    "    elif ind[0] == 4 and max(list(sc.values())) <= 2 and sc[ind[1]] != 2:\n",
    "        return 'unknown'\n",
    "    # HANDLE NN BEING RIGHT AND RULE-BASED BEING WRONG\n",
    "    else:\n",
    "        return mapping[ind[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
